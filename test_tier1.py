#!/usr/bin/env python3
"""
Quick test script to verify TIER 1 implementations are working correctly.
Run this before starting full training to catch issues early.

Usage:
    python test_tier1.py

Tests:
    1. MultiScaleTemporalAttention forward pass
    2. Self-supervised pre-training imports
    3. Config loading and validation
    4. Model instantiation with TIER 1 features
    5. Dummy forward pass with 7 temporal frames
"""

import torch
import torch.nn as nn
import yaml
import sys
import os

print("=" * 70)
print("TIER 1 IMPLEMENTATION TEST")
print("=" * 70)
print()

# Test 1: Import MultiScaleTemporalAttention
print("Test 1: Importing MultiScaleTemporalAttention...")
try:
    from src.pytorchmodel import MultiScaleTemporalAttention

    print("âœ“ MultiScaleTemporalAttention imported successfully")
except ImportError as e:
    print(f"âœ— FAILED to import MultiScaleTemporalAttention: {e}")
    sys.exit(1)

# Test 2: Import pre-training module
print("\nTest 2: Importing pretraining module...")
try:
    from src.pretraining import pretrain_encoder, ReconstructionDecoder

    print("âœ“ Pretraining module imported successfully")
except ImportError as e:
    print(f"âœ— FAILED to import pretraining: {e}")
    sys.exit(1)

# Test 3: Test MultiScaleTemporalAttention forward pass
print("\nTest 3: Testing MultiScaleTemporalAttention forward pass...")
try:
    feature_dim = 256
    seq_len = 7  # TIER 1: 7 temporal frames
    batch_size = 4

    # Create dummy input
    dummy_input = torch.randn(batch_size, seq_len, feature_dim)

    # Create module
    attention = MultiScaleTemporalAttention(feature_dim, num_heads=4)

    # Forward pass
    output, attn_weights = attention(dummy_input)

    # Check output shape
    assert output.shape == (batch_size, feature_dim), (
        f"Expected shape ({batch_size}, {feature_dim}), got {output.shape}"
    )

    print(f"âœ“ Forward pass successful")
    print(f"  Input shape: {dummy_input.shape}")
    print(f"  Output shape: {output.shape}")
    print(f"  Attention weights shape: {attn_weights.shape}")

except Exception as e:
    print(f"âœ— FAILED: {e}")
    import traceback

    traceback.print_exc()
    sys.exit(1)

# Test 4: Test ReconstructionDecoder
print("\nTest 4: Testing ReconstructionDecoder...")
try:
    feature_dim = 256
    image_shape = (440, 640)
    batch_size = 2

    # Create dummy features
    dummy_features = torch.randn(batch_size, feature_dim)

    # Create decoder
    decoder = ReconstructionDecoder(feature_dim, image_shape)

    # Forward pass
    reconstructed = decoder(dummy_features)

    # Check output shape
    expected_shape = (batch_size, 1, image_shape[0], image_shape[1])
    assert reconstructed.shape == expected_shape, (
        f"Expected shape {expected_shape}, got {reconstructed.shape}"
    )

    print(f"âœ“ Decoder forward pass successful")
    print(f"  Feature input shape: {dummy_features.shape}")
    print(f"  Reconstructed image shape: {reconstructed.shape}")

except Exception as e:
    print(f"âœ— FAILED: {e}")
    import traceback

    traceback.print_exc()
    sys.exit(1)

# Test 5: Load and validate config
print("\nTest 5: Loading and validating TIER 1 config...")
try:
    config_path = "configs/colab_optimized_full_tuned.yaml"

    if not os.path.exists(config_path):
        print(f"âœ— Config file not found: {config_path}")
        sys.exit(1)

    with open(config_path, "r") as f:
        config = yaml.safe_load(f)

    # Validate TIER 1 settings
    checks = {
        "temporal_frames": (config.get("temporal_frames"), 7),
        "use_multiscale_temporal": (config.get("use_multiscale_temporal"), True),
        "attention_heads": (config.get("attention_heads"), 4),
        "pretraining.enabled": (config.get("pretraining", {}).get("enabled"), True),
        "pretraining.epochs": (config.get("pretraining", {}).get("epochs", 0), 20),
    }

    all_passed = True
    for key, (actual, expected) in checks.items():
        if actual == expected:
            print(f"  âœ“ {key}: {actual}")
        else:
            print(f"  âœ— {key}: expected {expected}, got {actual}")
            all_passed = False

    if all_passed:
        print("âœ“ Config validation passed")
    else:
        print("âš  WARNING: Some config values don't match TIER 1 recommendations")
        print("  Training may still work, but results may differ from expected")

except Exception as e:
    print(f"âœ— FAILED to load config: {e}")
    sys.exit(1)

# Test 6: Instantiate full model with TIER 1 features
print("\nTest 6: Instantiating model with TIER 1 features...")
try:
    from src.pytorchmodel import MultimodalRegressionModel, get_model_config

    # Create model config
    temporal_frames = 7
    image_shape = (temporal_frames, 440, 640)

    model_config = get_model_config(
        image_shape=image_shape,
        temporal_frames=temporal_frames,
        memory_optimized=False,  # Test full model
    )

    # Add TIER 1 settings
    model_config["use_multiscale_temporal"] = True
    model_config["attention_heads"] = 4
    model_config["use_spatial_attention"] = True
    model_config["use_temporal_attention"] = True

    # Create model
    model = MultimodalRegressionModel(model_config)

    # Verify multi-scale attention is used
    is_multiscale = isinstance(model.temporal_attention, MultiScaleTemporalAttention)

    if is_multiscale:
        print("âœ“ Model uses MultiScaleTemporalAttention")
    else:
        print("âš  WARNING: Model not using MultiScaleTemporalAttention")
        print(f"  Actual type: {type(model.temporal_attention)}")

    # Count parameters
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    print(f"âœ“ Model instantiated successfully")
    print(f"  Total parameters: {total_params:,}")
    print(f"  Trainable parameters: {trainable_params:,}")

except Exception as e:
    print(f"âœ— FAILED to instantiate model: {e}")
    import traceback

    traceback.print_exc()
    sys.exit(1)

# Test 7: Test full forward pass with 7 frames
print("\nTest 7: Testing full forward pass with 7 temporal frames...")
try:
    batch_size = 2
    temporal_frames = 7
    h, w = 440, 640

    # Create dummy inputs
    dummy_images = torch.randn(batch_size, temporal_frames, h, w)
    dummy_param1 = torch.randn(batch_size, 1)
    dummy_param2 = torch.randn(batch_size, 1)

    # Forward pass
    model.eval()
    with torch.no_grad():
        output, _ = model(dummy_images, dummy_param1, dummy_param2)

    # Check output
    assert output.shape == (batch_size, 1), (
        f"Expected output shape ({batch_size}, 1), got {output.shape}"
    )

    print(f"âœ“ Forward pass successful with 7 frames")
    print(f"  Image input shape: {dummy_images.shape}")
    print(f"  Param1 input shape: {dummy_param1.shape}")
    print(f"  Param2 input shape: {dummy_param2.shape}")
    print(f"  Output shape: {output.shape}")
    print(f"  Output range: [{output.min().item():.4f}, {output.max().item():.4f}]")

except Exception as e:
    print(f"âœ— FAILED: {e}")
    import traceback

    traceback.print_exc()
    sys.exit(1)

# Test 8: Test with gradient checkpointing enabled
print("\nTest 8: Testing with gradient checkpointing...")
try:
    model_config["gradient_checkpointing"] = True
    model_gcp = MultimodalRegressionModel(model_config)

    # Training mode forward pass
    model_gcp.train()
    output, _ = model_gcp(dummy_images, dummy_param1, dummy_param2)

    # Backward pass
    loss = output.sum()
    loss.backward()

    print("âœ“ Gradient checkpointing works correctly")

except Exception as e:
    print(f"âœ— FAILED: {e}")
    import traceback

    traceback.print_exc()
    sys.exit(1)

# Test 9: Verify pre-training setup
print("\nTest 9: Testing pre-training setup...")
try:
    # Create a dummy data loader (not real data, just for testing)
    class DummyDataset(torch.utils.data.Dataset):
        def __len__(self):
            return 10

        def __getitem__(self, idx):
            return (
                torch.randn(7, 440, 640),  # images
                torch.randn(1),  # param1
                torch.randn(1),  # param2
            )

    dummy_dataset = DummyDataset()
    dummy_loader = torch.utils.data.DataLoader(
        dummy_dataset, batch_size=2, shuffle=True
    )

    # Test that pretrain_encoder function signature is correct
    import inspect

    sig = inspect.signature(pretrain_encoder)
    params = list(sig.parameters.keys())

    expected_params = [
        "model",
        "train_loader",
        "epochs",
        "lr",
        "device",
        "save_checkpoints",
        "checkpoint_dir",
    ]

    for param in expected_params:
        if param not in params:
            print(f"  âœ— Missing parameter: {param}")
        else:
            print(f"  âœ“ Parameter exists: {param}")

    print("âœ“ Pre-training setup verified")

except Exception as e:
    print(f"âœ— FAILED: {e}")
    import traceback

    traceback.print_exc()
    sys.exit(1)

# Final summary
print("\n" + "=" * 70)
print("TIER 1 TEST SUMMARY")
print("=" * 70)
print("âœ“ All tests passed!")
print()
print("TIER 1 Implementation Status:")
print("  âœ“ MultiScaleTemporalAttention: Working")
print("  âœ“ Self-supervised pre-training: Working")
print("  âœ“ ReconstructionDecoder: Working")
print("  âœ“ Config validation: Passed")
print("  âœ“ Model instantiation: Working")
print("  âœ“ Forward pass (7 frames): Working")
print("  âœ“ Gradient checkpointing: Working")
print("  âœ“ Pre-training setup: Verified")
print()
print("You are ready to run full TIER 1 training! ðŸš€")
print()
print("Next steps:")
print(
    "  1. Run training: python main.py --config configs/colab_optimized_full_tuned.yaml"
)
print("  2. Monitor progress in TensorBoard")
print("  3. Compare results to baseline (RÂ² = -0.0927)")
print("  4. Target: RÂ² > 0.15, MAE < 0.30 km")
print("=" * 70)
