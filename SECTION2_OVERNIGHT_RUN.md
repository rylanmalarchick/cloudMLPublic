# SECTION 2: OVERNIGHT RUN SUMMARY

## ‚úÖ Pre-Flight Checklist Complete

All configurations have been verified and updated for local execution.

### Configuration Status

| Item | Status | Details |
|------|--------|---------|
| **Data paths** | ‚úÖ Updated | `/home/rylan/Documents/research/NASA/programDirectory/data/` |
| **Output paths** | ‚úÖ Updated | Local directories (`./logs/`, `./results/`, `./models/`) |
| **Flight files** | ‚úÖ Verified | Correct filenames with revision numbers |
| **HPC mode** | ‚úÖ Disabled | `hpc_mode: false` |
| **Torch compile** | ‚úÖ Disabled | `torch_compile: false` (for stability) |
| **Virtual env** | ‚úÖ Active | Python environment ready |
| **Directories** | ‚úÖ Created | `logs/`, `models/`, `results/`, `diagnostics/results/` |

---

## üöÄ Execution Plan

### Automated Run Script
**File**: `scripts/run_section2_automated.sh`

This script will run **6 experiments sequentially** without user interaction:

1. **Baseline (Œª=0.0)** - 15 epochs (~30-60 min)
2. **Lambda=0.5** - 15 epochs (~30-60 min)
3. **Lambda=1.0** - 15 epochs (~30-60 min)
4. **Lambda=2.0** - 15 epochs (~30-60 min)
5. **Lambda=5.0** - 15 epochs (~30-60 min)
6. **Lambda=10.0** - 15 epochs (~30-60 min)

**Estimated Total Time**: 3-6 hours

---

## üìã Experiment Details

Each experiment will:
- Train for **15 epochs** (sufficient to observe variance collapse or recovery)
- Use **batch_size=20** (optimized for local GPU)
- Save logs to `logs/section2_*_YYYYMMDD_HHMMSS.log`
- Track metrics: R¬≤, Variance Ratio, Base Loss, Variance Loss

### Key Differences Between Experiments

| Experiment | variance_lambda | Expected Behavior |
|------------|-----------------|-------------------|
| Baseline | 0.0 | **Collapse**: R¬≤ < 0, variance ratio < 20% |
| Lambda 0.5 | 0.5 | Partial recovery |
| Lambda 1.0 | 1.0 | Moderate regularization (likely optimal) |
| Lambda 2.0 | 2.0 | Strong regularization |
| Lambda 5.0 | 5.0 | Very strong regularization |
| Lambda 10.0 | 10.0 | Potential instability |

---

## üéØ What to Expect

### Baseline (Œª=0.0) - Control Experiment
**Purpose**: Quantify the collapse phenomenon

**Expected Output**:
```
Validation R¬≤: -0.05 to -0.20 (negative)
Variance Ratio: 5-20% (collapsed)
Prediction distribution: Narrow spike near mean (0.83 km)
```

This confirms the problem we're trying to solve.

### Optimal Lambda (likely Œª=1.0 or Œª=2.0)
**Purpose**: Demonstrate variance preservation fixes collapse

**Expected Output**:
```
Validation R¬≤: 0.3 to 0.5+ (positive, approaching simple baselines)
Variance Ratio: 80-120% (good distribution matching)
Prediction distribution: Spread matches target distribution
```

This proves the fix works.

### High Lambda (Œª=10.0)
**Purpose**: Test limits of regularization strength

**Expected Output**:
```
Possible instability: NaN losses, training divergence
OR: Over-dispersed predictions, lower R¬≤
```

This defines the upper boundary.

---

## üìä Monitoring Progress

### During Execution

The script will output progress to both:
1. **Console** (stdout/stderr)
2. **Log files** in `logs/section2_*.log`

You can monitor in real-time with:
```bash
# Watch latest log file
tail -f logs/section2_*.log | grep -E "(Epoch|R¬≤|Variance)"

# Check all completed experiments
ls -lh logs/section2_*.log

# Quick grep for final results
grep "Final" logs/section2_*.log
```

### Key Metrics to Watch

Each epoch should log:
- **Train Loss**: Should decrease
- **Val Loss**: Should decrease (may plateau)
- **Val R¬≤**: Should increase (target: > 0)
- **Variance Ratio**: Should approach 100%
- **Base Loss**: Huber component
- **Variance Loss**: Penalty component

---

## üîç After Completion

### Step 1: Verify All Runs Completed
```bash
# Check for 6 log files
ls -1 logs/section2_*.log | wc -l
# Should output: 6

# Check for errors
grep -i "error\|fail\|nan" logs/section2_*.log
```

### Step 2: Run Analysis Scripts
```bash
# Activate environment
source venv/bin/activate

# Generate Table 2
python scripts/aggregate_section2_results.py

# Generate Figure 2 (distribution plots)
python scripts/plot_section2_distributions.py

# View results
cat diagnostics/results/section2_table2.txt
```

### Step 3: Review Results

**Key Questions to Answer**:
1. Did baseline (Œª=0.0) show collapse? (R¬≤ < 0, variance < 20%)
2. Which lambda achieved highest R¬≤?
3. Which lambda has variance ratio closest to 100%?
4. Were any runs unstable? (NaNs, explosions)
5. Do prediction distributions visually match targets?

### Step 4: Select Optimal Lambda

**Selection Criteria**:
- ‚úÖ Highest validation R¬≤ (primary)
- ‚úÖ Variance ratio 80-120% (good distribution matching)
- ‚úÖ Stable training (smooth curves)
- ‚úÖ Visual distribution matching

**Likely Outcome**: Œª = 1.0 or Œª = 2.0

---

## üìà Expected Timeline

| Time | Event |
|------|-------|
| **T+0:00** | Start: Baseline (Œª=0.0) |
| **T+0:45** | Complete: Baseline |
| **T+0:50** | Start: Œª=0.5 |
| **T+1:35** | Complete: Œª=0.5 |
| **T+1:40** | Start: Œª=1.0 |
| **T+2:25** | Complete: Œª=1.0 |
| **T+2:30** | Start: Œª=2.0 |
| **T+3:15** | Complete: Œª=2.0 |
| **T+3:20** | Start: Œª=5.0 |
| **T+4:05** | Complete: Œª=5.0 |
| **T+4:10** | Start: Œª=10.0 |
| **T+4:55** | Complete: Œª=10.0 |
| **T+5:00** | **ALL COMPLETE** |

*(Times are approximate, assuming ~45 min per experiment)*

---

## üõ°Ô∏è Error Handling

The script includes:
- ‚úÖ Exit on undefined variables
- ‚úÖ Continues if one experiment fails
- ‚úÖ Logs all output (stdout + stderr)
- ‚úÖ Timestamp for each experiment

If an experiment fails:
1. Check the log file for that experiment
2. Common issues:
   - Out of memory ‚Üí Reduce batch_size
   - CUDA error ‚Üí Check GPU availability
   - Data loading error ‚Üí Verify file paths
3. Re-run just that experiment manually:
   ```bash
   python main.py --config configs/section2_lambda_X.X.yaml
   ```

---

## üíæ Output Files

After completion, you should have:

### Log Files (6 total)
```
logs/section2_baseline_collapse_YYYYMMDD_HHMMSS.log
logs/section2_lambda_0.5_YYYYMMDD_HHMMSS.log
logs/section2_lambda_1.0_YYYYMMDD_HHMMSS.log
logs/section2_lambda_2.0_YYYYMMDD_HHMMSS.log
logs/section2_lambda_5.0_YYYYMMDD_HHMMSS.log
logs/section2_lambda_10.0_YYYYMMDD_HHMMSS.log
```

### Model Checkpoints
```
models/section2_baseline_collapse_best.pth (maybe)
models/section2_lambda_*.pth
```

### Result Files (after analysis scripts)
```
diagnostics/results/section2_table2.csv
diagnostics/results/section2_table2.txt
diagnostics/results/section2_summary.json
diagnostics/results/section2_distributions.png
diagnostics/results/section2_training_curves.png
```

---

## üéì Scientific Deliverables

Upon completion, Section 2 will provide:

1. **Table 2**: Quantitative comparison of all variance_lambda values
   - Columns: lambda, R¬≤, variance ratio, base loss, variance loss, stability
   - Shows progression from collapse to recovery

2. **Figure 2**: Grid of prediction distributions
   - Visual proof of variance preservation
   - Comparison to target distribution

3. **Recommendation**: Optimal lambda for Section 3
   - Documented justification
   - Ready for architectural ablation studies

4. **Scientific Evidence**:
   - Quantified collapse: "R¬≤ = -0.XX with Œª=0"
   - Quantified recovery: "R¬≤ = 0.XX with Œª=Y"
   - Proves training pathology, not data limitation

---

## üö¶ Status Checkpoints

### Before Starting
- [x] Paths updated to local filesystem
- [x] Flight filenames corrected
- [x] Virtual environment activated
- [x] Output directories created
- [x] Config files validated
- [x] Data files accessible

### Ready to Launch
**Command to start overnight run**:
```bash
cd /home/rylan/Documents/research/NASA/programDirectory/cloudMLPublic
nohup bash scripts/run_section2_automated.sh > section2_run.log 2>&1 &
```

This runs in background, survives terminal disconnect, and logs everything.

**Check status**:
```bash
tail -f section2_run.log
```

**Or start in foreground** (if staying connected):
```bash
bash scripts/run_section2_automated.sh
```

---

## üìû Quick Reference

```bash
# Start overnight run (background, survives disconnect)
nohup bash scripts/run_section2_automated.sh > section2_run.log 2>&1 &

# Monitor progress
tail -f section2_run.log

# Check process is running
ps aux | grep run_section2

# After completion - analyze results
python scripts/aggregate_section2_results.py
python scripts/plot_section2_distributions.py
cat diagnostics/results/section2_table2.txt
```

---

## ‚ú® What Happens Next

After Section 2 completes successfully:

1. **Review Table 2** - Identify optimal lambda
2. **Update Section 3 configs** - Use optimal lambda throughout
3. **Proceed to Section 3** - Architectural Ablation Study
   - Simple CNN baseline
   - + Spatial attention
   - + Temporal attention
   - + Multi-scale temporal attention

Each section builds on the previous, creating a complete research narrative.

---

**Status**: ‚úÖ Ready for overnight execution  
**Estimated Completion**: 3-6 hours  
**Next Milestone**: Section 3 - Architectural Ablation Study

**Good luck! The experiments are ready to run.** üöÄ