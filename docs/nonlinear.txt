





Data-driven identification of nonlinear dynamical systems with LSTM autoencoders and Normalizing Flows

Abdolvahhab Rostamijavanani · Shanwu Li · Yongchao Yang









Abstract While linear systems have been useful in solving problems across different fields, the need for im- proved performance and efficiency has prompted them to operate in nonlinear modes. As a result, nonlinear models are now essential for the design and control of these systems. However, identifying a nonlinear sys- tem is more complicated than identifying a linear one. Therefore, modeling and identifying nonlinear systems are crucial for the design, manufacturing, and testing of complex systems. This study presents using advanced nonlinear methods based on deep learning for system identification. Two deep neural network models, LSTM autoencoder and Normalizing Flows, are explored for their potential to extract temporal features from time series data and relate them to system parameters, re- spectively. The presented framework offers a nonlinear approach to system identification, enabling it to han- dle complex systems. As case studies, we consider Duff- ing and Lorenz systems, as well as fluid flows such as flows over a cylinder and the 2-D lid-driven cavity prob- lem. The results indicate that the presented framework is capable of capturing features and effectively relating them to system parameters, satisfying the identification requirements of nonlinear systems.


Keywords Nonlinear dynamics · Dynamical systems · System Identification · Deep learning · Normalizing Flows



Abdolvahhab Rostamijavanani (Corresponding Author) Department of Mechanical Engineering-Engineering Mechan- ics, Michigan Technological University, Houghton, Michigan 49931, USA
E-mail: arostami@mtu.edu
1 
Introduction

Linear systems have been successfully used to solve various problems across different fields. However, the demand for better performance and efficiency pushes these systems to operate in nonlinear modes, which necessitates the use of nonlinear models for their de- sign and control. Identifying a nonlinear system is a much more intricate process than identifying a linear one. Therefore, it is essential to model and identify non- linear systems for designing, manufacturing, and test- ing complex systems. The models for nonlinear systems can be broadly categorized into White Box [1-4], Black Box [5-9], and Grey Box [8, 10-13] modeling to identify the system [14]. White Box modeling is effective but challenging as it requires accurate physics knowledge and is difficult to generalize to various systems. Black Box modeling is an alternative to physics-based model- ing and characterizes the model based on experimental data, making it easy to use but less interpretable.
   Black Box modeling deals with estimating a func- tion by hypothesizing a functional relationship between input and output, making it simpler but difficult to estimate and interpret the parameters. Experiment de- sign becomes more challenging, model selection requires more careful consideration, and parameter estimation is more complex. Therefore, it is important to go be- yond traditional linear methods of identification and move towards advanced nonlinear methods of identi- fication. Ideally, a nonlinear system identification ap- proach should be recommended when the function pre- processing step indicates that the distortion levels are excessively high and significantly surpass the data noise floor [14].
   The Black Box model can be solved using several techniques, both classical [15] and modern [16], such as neural networks. The use of data-driven approaches



has become increasingly popular in modeling nonlinear systems due to the advancements in machine learning and deep learning technology. The fundamental archi- tecture of deep learning, known as deep neural networks (DNNs), has proven to be particularly effective in cap- turing the intrinsic features of complex systems. DNNs offer a remarkable modeling capacity and learning flexi- bility, allowing them to represent complex relationships in a hierarchical manner. The universal approximation theorem [17, 18] is a significant result in the field of deep learning. It states that a DNN with an adequate number of neural units and nonlinear activations can represent a wide range of intricate functions. For ex- ample, DNNs have the capability to learn and repre- sent complex nonlinear relationships between input and output variables. DNNs also provide the flexibility of adapting the network architecture to different tasks. This means that the architecture of the DNN can be tailored to the specific characteristics of the problem at hand, such as the identification of nonlinear dynamics. This adaptive design of the network architecture en- ables DNNs to achieve high accuracy in complex mod- eling tasks, making them a powerful tool in the field of nonlinear systems. LSTM autoencoder and Normal- izing Flows are two deep learning models that can be used for nonlinear system identification, each with its unique features.
   LSTM autoencoder [19-21] can be used to extract temporal features of dynamical systems from time se- ries data, which can then be used for further analysis or modeling. This approach can be useful in various ap- plications such as signal processing, system identifica- tion, and anomaly detection. Normalizing Flows [22-25] is a class of generative models that aims to learn the underlying probability distribution of a given dataset. By using Normalizing Flows, it is possible to capture the underlying probability distribution of the data and use it to generate new data samples or infer the latent variables that explain the observed data. By combining these two models (creating a black-box), we can extract meaningful temporal features from the time series data using LSTM autoencoder and use Normalizing Flows to map these features to system parameters. This can facilitate nonlinear system identification in various ap- plications such as control, prediction, and modeling of complex systems
   Therefore, the primary objective of this study is to create a deep learning framework capable of iden- tifying nonlinear systems. The framework is designed to address two main challenges. The first challenge is the extraction of features from the time series data (i.e., response data) of the dynamical system using a LSTM-encoder. The second challenge involves relating

these features to system parameters using a Normaliz- ing Flows framework.To put it differently, the black box consists of two models. The first model is responsible for capturing time-related features of the data (e.g., signal frequency), while the second model establishes a rela- tionship between these features and system parameters. By utilizing deep learning, this process guarantees non- linear transformations, ensuring that the system iden- tification is based on a nonlinear approach.


2 Methodology: Normalizing Flows concept

Normalizing Flows is a generative model [22-25] that efficiently and accurately estimates density by produc- ing tractable distributions. In contrast, GANs [26-28] and VAEs [29-31] do not explicitly learn the probabil- ity function of training data. Instead, GANs generate similar data to deceive the discriminator in a min-max game until it reaches a saturation point where it can- not differentiate between real and fake samples. VAEs, on the other hand, learn to identify variational infer- ence in latent space and generate data using a decoder. However, neither GANs nor VAEs can learn the real probability density functions (PDFs) of real data. Nor- malizing Flows, a rigorous generative method, learns the real PDF of a dataset by using invertible and dif- ferentiable functions. To create a random variable X with a complicated distribution P, Normalizing Flows applies an invertible and differentiable function (f) to a random variable Z with a simple distribution, such as a standard normal distribution Z ~ N (0, 1) using this formula: X = f (Z) ~ P and Z = f-1(X). The change of variables method can be used to calculate the transferred distribution P as follows:

?f
log P(X) = log P(Z) - log |   (Z)|	(1)
?Z

However, finding a single function (bijector) that trans- fers the distribution in the desired manner is not an easy task. In cases where the target distribution P is highly complex, a simple f (e.g., a scale or shift function) is not adequate. To address this issue, we can create a more intricate PDF by composing bijectors with one another, forming a more complex chain of bijectors. The follow- ing example demonstrates this approach:

f = fk ? fk-1 ? ...f1	(2)

A Normalizing Flows involves transforming a base dis- tribution (such as the standard normal distribution) into a more complex target distribution by applying



a sequence of bijectors one after another:

Z0 = Z
Zk = fk(Zk-1)
X = Zk




(3)

can be used to predict the system's future behavior. In order to achieve this objective, we utilize a function de- noted as F , which establishes the relationship between the output of the system, R ? Rn, and the parame- ters that govern its behavior, Psys ? Rs where n and s are the number of degrees of freedom of the system

In addition, the transformed (target) distribution can be obtained by summing the contributions from each bijector:

and number of corresponding system parameters, re- spectively. The formulation is as beloow:

Psys = F (R)	(5)

i=k
log P(X) = log P(Z) -	log |	i  (Z
?Zi-1


i-1

)|	(4)


However, this relationship can be complex, and different

i=1

To obtain the target distribution, we can assign each fi simple functions such as scale and shift, along with a basic nonlinearity such as sigmoid or ReLU function. It's worth noting that each fi has parameters (like scale and shift values) that can be learned from training data using maximum likelihood estimation.


2.1 Models with Normalizing Flows

All Normalizing Flows models share the properties of being both invertible and differentiable. The RealNVP model (Real-valued Non-Volume Preserving)[32] can be constructed by stacking a sequence of bijectors that have easily computable Jacobian determinants and are easily invertible. An earlier alternative to RealNVP is

sets of parameters may produce similar system behav- ior, making it challenging to determine the correct pa- rameters. Therefore, we also employ another function, K, which connects some of the system's features (f ), such as its frequency, to the parameters.

Psys = K(f )	(6)

while f is achieved directly form system output (R) by the function G as bellow:

f = G(R)	(7)

As for fluid flow systems, due to their high-dimensionality, we first attempt to capture the spatial features be- fore extracting the temporal features and subsequently the system parameters. To achieve this, we use R' ?

Non-linear Independent Component Estimation (NICE)[33].Rm (m < n) as follows:
Autoregressive models are another type of Normaliz-

ing Flows that have fast-to-compute Jacobian matrices because each fi (see equation. (20)) only depends on Z1, ..., Zi. Therefore,  ?fi = 0 whenever j > i, resulting in a lower triangular Jacobian matrix, with the determi- nant being a simple product of the diagonal elements. Additionally, the joint density P(X) can be modeled as the product of conditionals  iP(X i|X 1 : i - 1). In this paper, we utilize a masked autoregressive flow model.


3 Problem formulation

System identification is a mathematical approach that aims to uncover the fundamental aspects of a system that control its behavior. This method is particularly useful in solving inverse problems where we know the output of a system, such as displacement or velocity trajectories of a Duffing system or the velocity or pres- sure field of a fluid flow system, but we want to deter- mine the system's parameters, denoted by Psys. Given the input-output data of a nonlinear system, the goal of nonlinear system identification is to determine the system's underlying dynamics and parameters, which

R' = t (R)	(8)

where t is a function that captures the spatial features. We are able to utilize R' in place of R in equations (18) and (20) for identifying the system parameters.


4 Deep learning framework

4.1 Objective

Due to the lack of a general mathematical framework for nonlinear system identification, the primary goal of this approach is to identify the parameters of a given dynamical system. Specifically, by analyzing time-series data obtained from the Duffing system, we aim to iden- tify important parameters such as the mass, stiffness, and nonlinearity of the system. Similarly, in fluid flow data, we can determine the Reynolds number by analyz- ing two-dimensional flow fields over time. This frame- work is capable of capturing unique features of dynam- ical systems and extracting their corresponding param- eters.



	     
??(0)~??0(??(0))	??(??)~????(??(??))	??(??)~????(??(??))

Fig. 1 The concept of Normalizing Flows can be defined as the process of transforming a simple probability distribution function (P0) to the original, more complex distribution function (Pk) by utilizing bijectors.


????





????


??????????????: ?? = ??-1(??)


??????????????: ?? = ??(??)

??0





??0


Fig. 2 In the Normalizing Flows concept, the dependency between the two original coordinates of a 2-DOF Duffing system can be reduced by passing through Normalizing Flows layers. Here, Z0 represents the decomposed modal coordinates, and X refers to the original coordinates.


a	b





c	d	e

Fig. 3 Case studies: a: 2 DOF Duffing system b: Lorenz system c: Stream-wise velocity over a cylinder d: Transverse velocity over a cylinder e: Vorticity of a 2-D driven-lid cavityproblem

??

Fig. 4 The architecture of the framework presented for non-fluid case studies involves two main components. Firstly, the temporal features (f) of the input data (i.e., trajectories: X) are extracted using LSTM-Encoder (?). Next, Normalizing Flows (NF) is utilized to establish a relationship between these temporal features and the system parameters (Y ). In order to ensure that the temporal features of the input data represent the most critical information, a LSTM-Decoder (?-1) is utilized to reconstruct the data.


4.2 Deep Normalizing flow framework

4.2.1 2-DOF Duffing oscillator and Lorenz Systems

first loss function utilized is probability density esti- mation through Normalizing flow. The loss function is as follows:
i=ns

One of the examples presented in this study is the 2- DOF Duffing oscillator. Duffing systems are composed of three parameters: mass, stiffness, and nonlinearity

1
LN = -
ns

log P(f(i))	(10)
i=1

coefficients (M, K, NL coef ). Each study modifies one of these parameters while holding the other two con- stant. Another case study involves the Lorenz systems, which are chaotic dynamical systems controlled by three parameters ( s, ß, ? ). To extract the primary features of the data, such as frequency, the time series data is encoded using an LSTM-Encoder and subsequently de- coded to return to the original data. Once the features are extracted, they are passed to the Normalizing flow to identify the system parameters.
   The framework presented captures the temporal char- acteristics of the system and establishes a connection with system parameters. The overall loss function is defined as follows:

where f is the features extracted from LSTM-autoencoder,
(i) denotes the index number of training dataset and
ns represents the number of training samples.
2. Lrec-lstm: The time series data is reconstructed us- ing an LSTM-Autoencoder. The LSTM-encoder acts as a forward nonlinear transformation that converts the original time series data to temporal features in the latent intrinsic space. The decoder subse- quently transforms the feature coordinates back to their original coordinates. The associated loss is tra-
jectory reconstruction, which force the LSTM-Autoencoder to reconstruct the original time series data from
the latent space. The corresponding loss is therefore minimizing:
i=ns

L = aNF LNF + arec-lstmLrec-lstm + arec-f Lrec-f (9)

 1  L ||X - ?-1 (? (X)) ||(i)

(11)

Loss functions used in in this case are expressed as be-

ns
i=1

MSE

low:
1. LNF : The loss function for temporal features (f) reconstruction is negative log-likelihood (NLL). The

where ns represents the number of training samples and (i) denotes the index number assigned to each sample.




Fig. 5 The architecture of the framework presented for fluid case studies involves three main components. Firstly, the spatial features (M') of the flow field (M) is extracted using a CNN-Encoder (t ) .Secondly, the temporal features (f) of the spatial features data are extracted using LSTM-Encoder. Next, Normalizing Flows (NF) is utilized to establish a relationship between these temporal features and the system parameters (Y ). In order to ensure that the spatial and temporal features of the input data represent the most critical information, a CNN-Decoder (t-1) and a LSTM-Decoder (?-1) are used respectively to reconstruct the data.


3. Lrec-f : Auxiliary feature reconstruction. In order to establish a connection between system parameters and temporal features, we provide the correspond- ing system parameters of each sample as input to the NF model and connect them to the temporal features using the following loss function:
i=ns

problem with a driven lid. Initially, the 2-D spatial time series data (M) is inputted into a CNN-Encoder (t ), which reduces the spatial size and extracts the most significant spatial features/patterns of flow (M'). The spatial features are then sent to a LSTM-encoder (?) to extract the temporal features (f) from the spatial fea- tures. Additionally, the spatial features are processed

 1  L ||f - NF (Y ))||(i)



(12)

by a CNN-decoder (t-1) to restore them to the orig-



where Y is the corresponding system parameters of X data and f is the corresponding temporal features extracted by the LSTM-Encoder (see Fig. 4)

4.2.2 Flow passing a cylinder and 2-D cavity problem

In this section, we present another example where we analyze a 2-D flow over a cylinder and a 2-D cavity

tures are then sent to the NF model to map to the
flow parameter (Y ), Reynolds number. Furthermore, the LSTM-Decoders (?-1) are employed to convert the extracted temporal features to spatial features. It is worth noting that the CNN-Decoder and LSTM-Decoder
assist in determining whether the extracted spatial/temporal features are reliable.


a






real Predicted


b








c
         	


Fig. 6 system parameters identification of 2-D Duffing systems. a Only the stiffness (K) of system changes over samples. Comparison of the parameters predicted by the framework and the ground truths and the distribution of predicted and ground truths parameters. b Only the mass (M) of system changes over samples. c Only the nonlinearity (NL Coef) of system changes over samples.


The overall loss function is defined as follows:
2. 
Lrec-CNN : Reconstruction of time series 2-D flow by CNN-Autoencoder. To decrease the dimension-

L = aNF LNF +arec-lstmLrec-lstm+arec-CNN Lrec-CNN +areca-lfitLyreocf-tfhe flow data, a CNN-Autoencoder is con-



The regarding loss functions are as:

(13)

structed. In order to guarantee that the extracted spatial features provide the most optimal low-dimensional representation of the flow, a reconstruction loss func-

1. Reconstruction of parameters loss function: The neg- ative log-likelihood (NLL) loss function is utilized
for Normalizing flow probability density estimation (sim-

tion is applied in the following manner:

i=ns
||M - t-1 (t (M)) ||(i)



(15)

ilar to the approach we used for the Duffing and Lorenz systems). The loss function is defined as be-

ns
i=1

MSE

low:

1
LN = -ns



i=ns
log P(f(i))	(14)
i=1
3. 
Lrec-lstm: Reconstruction of time series of spatial
features by LSTM-Autoencoder. The subsequent step involves extracting the most crucial temporal fea- tures from the time series of spatial features. A re- construction loss function is utilized to achieve this

where f is the features extracted from LSTM-autoencoder and (i) denotes the index number of training dataset.

aim. The purpose of this function is to ensure that these extracted temporal features are suitable for

a
         	


b







Fig. 7 system parameters identification of Lorenz systems. a Only parameter s of system changes over samples. Comparison of the parameters predicted by the framework and the ground truths and the distribution of predicted and ground truths parameters. b Only parameter ? of system changes over samples.






















Fig. 8 system parameters identification of Lorenz systems. Two system parameters (s and ?) change together over samples. Comparison of the parameters predicted by the framework and the ground truths and the distribution of predicted and ground truths parameters show the performance decreases as the situation is more complex for the framework compared to single- parameter identification.



a	Time_step:1

Time_step:25

Time_step:40	b


Real:100
Predicted:102



Real:135	c
Predicted:134




Real:174 Predicted:174


Fig. 9 system parameters identification of flow over a cylinder (stream-wise velocity). a Three Reynolds numbers identified by framework using a sequence of flow fields. b Comparison of the parameters predicted by the framework and the ground truths and the distribution of predicted and ground truths parameters. c The error between the identified system parameters and the ground truth values.


a	Time_step:1


Time_step:25

Time_step:40	b


Real:100 Predicted:102



Real:135	c
Predicted:135




Real:174 Predicted:174


Fig. 10 system parameters identification of flow over a cylinder (transverse velocity). a Three Reynolds numbers identified by framework using a sequence of flow fields. b Comparison of the parameters predicted by the framework and the ground truths and the distribution of predicted and ground truths parameters. c The error between the identified system parameters and the ground truth values.


converting back to the original time series spatial features. This is achieved by minimizing the loss function as follows:
i=ns

we provide the corresponding system parameters of each sample as input to the NF model and connect them to the temporal features using the following loss function:

 1  L ||M' - ?-1 (? (M')) ||(i)



(16)

4. Lrec-f : Auxiliary feature reconstruction. In order to establish a connection between system param-



i=ns
||f - NF (Y ))||(i)



(17)




a	Time_step:10


Time_step:20

Time_step:30	b


Real:1000 Predicted:953


Real:3000	c
Predicted:3209



Real:6000 Predicted:6487


Fig. 11 system parameters identification of vorticity of a 2-D lid-driven cavity problem. a Three Reynolds numbers identified by framework using a sequence of flow fields. b Comparison of the parameters predicted by the framework and the ground truths and the distribution of predicted and ground truths parameters. c The error between the identified system parameters and the ground truth values.

Velocity (u)	Velocity (v)	Vorticity

Fig. 12 The effect of Reynolds number on the performance of the presented framework for three case studies.


where Y is the corresponding system parameters of M data and f is the corresponding temporal fea- tures extracted by the LSTM-Encoder.

4.2.3 Network architecture and training

Normalizing flow architecture: Autoregressive models are potent models for probability density estimation in normalizing flows. RealNVP and NICE are specific types of autoregressive models. In this study, we incor- porate multiple autoregressive models into our frame- work. Each layer of the model comprises three dense layers, each with 512 neurons. We use nonlinear activa- tion functions for all layers because we aim to achieve nonlinear transformation/identification. Keras, a high- level API in Tensorflow, offers various nonlinear activa- tion functions such as Relu, Sigmoid, and tanh. Relu is among the most widely used functions due to its faster training run time [34], which we employ in our networks. After each autoregressive layer, we apply a

permutation layer because normalizing flow layers only operate on a portion of the data, leaving the rest un- changed. Therefore, we rearrange the data spaces to ensure that all data undergo nonlinear transformation through the network (see Fig. 5).


LSTM-Autoencoder: The LSTM-Autoencoder is an ef- ficient model for extracting temporal features from time series data. We utilized this model to extract relevant features and correlated them with system parameters in this study. We applied this model in two different case studies: one involving fluid flow and another non- fluid flow. The architecture of this model, including the number of layers and neurons for each sub-model, is reported in Table 2.


CNN-Autoencoder: Some parts of the network archi- tecture relies on a convolutional autoencoder. The con- volutional layer is responsible for extracting the most



critical flow field features, while the pooling layer re- duces the flow's degree of freedom in the encoder block. By using these layers in the encoder, we obtain more compressed fields that contain valuable flow informa- tion. Once the latent layers capture the intrinsic flow physics, we use upsampling and convolutional layers in the decoder block to reconstruct the original flow field. To preserve the size of the reconstructed flow field, we utilize fully-connected layers, reshape layers, and flat- ten layers.
   We use the Adam optimizer with a slow learning rate of a = 1e - 5 for both models. It is important to note that depending on the case study, all three models (for flow data) or two models (for Duffing and Lorenz systems) are trained simultaneously. This means that all weights are shared and modified during the training phase. We used the Xavier initialization method [35] to initialize the weights of each model. We evaluated the performance of the DNN across various training ses- sions by conducting hyperparameter tuning. We tested different sets of hyperparameters (weights of loss func- tions), and the results are based on the hyperparam- eters that yield the minimum validation errors (Table 3).

4.3 Datasets for training and testing

To generate datasets for Duffing and Lorenz systems, we use the ode45 solver in MATLAB to solve the ordi- nary differential equations of MDOF systems, and ob- tain training and testing data for each scenario by ran- domly sampling a single parameter from a normal dis- tribution while keeping the rest fixed. For Duffing sys- tems where stiffness changes, we sample stiffness from a normal standard distribution with mean and stan- dard deviation identical to those in the base distribu- tion used in the DNN framework, and the other pa- rameters are fixed at specific values. Similarly, for the cases where mass or nonlinearity changes, we fix the other two parameters and randomly sample the chang- ing parameter from the corresponding normal distri- bution. Specifically, the training/test data for stiffness changes come from K ~ N (5, 1), M ~ N (5, 0), g ~

by sampling it from a normal distribution with mean 28 and standard deviation 2, and the other parame- ters are fixed at specific values, i.e., s ~ N (10, 0), ß ~ N (8/3, 0), ? ~ N (28, 2). In a third scenario, we change the values of s and ? while keeping ß constant, i.e., s ~ N (10, 2), ß ~ N (8/3, 0), ? ~ N (28, 2). This process allows us to generate a range of datasets with different parameter combinations, which we can then use to train and evaluate our DNN models.
   In the study of streamwise/transverse flow over a cylinder, we use a grid of 96 by 192 evenly spaced points to examine 100 different samples for training and 30 samples for testing, each consisting of 50 time steps. It is important to note that the Reynolds numbers are randomly sampled from a normal distribution with a mean of 150 and a standard deviation of 25. For the cavity problem, we adopt a similar approach by using a grid size of 192 by 192 and sampling Reynolds numbers from a normal distribution with a mean of 450 and a standard deviation of 25. In this case, we examine 100 different samples for training and 30 samples for testing, each containing 30 time steps. This approach allows us to generate a range of datasets with different Reynolds numbers, which we can use to train and evaluate our models for these flow problems.


5 Result and Discussion

5.1 2-DOF Duffing oscillator

In the field of dynamic analysis, Duffing systems have been frequently used as case studies. In this section, we present a two-dimensional Duffing system as an exam- ple. The governing equation for this system is given by Eq. (18):
Mxš + Cx? + Kx + g = 0	(18)
where [M], [C], and [K] are the mass, damping, and stiffness matrices, respectively. x is the displacement vector (refer to Fig. 3), and g is the nonlinear term in the equation that characterizes the nonlinearity inten- sity. The expression for g is given by Eq. (19):

N (0.3, 0), the training/test data for mass changes come

? µ1k1d3 - µ2k2d3 1	? d1 1

? x1	1

from M ~ N (5, 1), K ~ N (5, 0), g ~ N (0.3, 0), and the

µ2k2d3 - µ3k3d3

d2	x2 - x1

2	3
training/test data for nonlinearity changes come from
K ~ N (5, 0), M ~ N (5, 0), g ~ N (0.3, 0.1). We follow

(19)

a similar approach for the Lorenz system, where we change only one or two parameters while keeping the rest constant in order to generate different scenarios. In one scenario, we randomly sample the values of the pa- rameters as s ~ N (10, 2), ß ~ N (8/3, 0), ? ~ N (28, 0), while in another scenario we change the value of ?

In this system, Rayleigh damping is assumed with the definition of [C]=q [k] where q stands for the damping coefficient.
   We first test the effectiveness of our presented NF- DNN with a 2-DOF nonlinear Duffing system. The goal is to identify one of the system parameters, including



Block
LST M layer
MaxPooling  layer
Dense layer
CNN-Encoder
6 (3 × 3)
6 (2 × 2)
-
CNN-Decoder
6 (3 × 3)
6 (2 × 2)
1
Table 1 CNN-Autoencoder architecture



Block	LST M layer	Dense layer

LSTM-Encoder	3	-
LSTM-Decoder	4	1
Table 2 LSTM-Autoencoder architecture



Case tudy
aNF
arec-lstm
arec-CNN
arec-f
Duffing-Lorenz
1
1
1
1
Flow over a cyllinder-Cavity problem
1
1
1
1
Table 3 Loss weights




the stiffness (k), mass (m), and nonlinearity coefficient, by first extracting features from the time series data and then using the neural network to compute the pa- rameter. It is worth noting that only one parameter is varied, and a set of time series data is generated for training. Figure. 6 shows the predicted parameters for three different scenarios, where each scenario involves changing only one parameter. The left plots present the predicted parameters for the test dataset (size 30). For each test sample, the middle plots display the corre- sponding error of the predicted values, and the right plots show the differences between the real and pre- dicted distributions of system parameters. The results indicate that the proposed DNN effectively extracts fea- tures from time series data and correlates them with system parameters, as the average error of these pre- dictions is generally less than 5 percent.


5.2 Lorenz system

The Lorenz system, a typical example of a nonlinear dynamical system, is studied in this work. The system is governed by three equations, as shown below:
dx
= s(y - x)
dt


behavior that is dependent on these three parameters, making it difficult to predict its dynamic behavior. How- ever, in the following, it is demonstrated that the pro- posed data-driven method is capable of capturing the system's dynamics and identify system parameters.
   The presented method's ability to identify system parameters of the Lorenz system is demonstrated in Figure 7. Specifically, Figure 7(a) examines the impact of changing parameter s by comparing predicted and actual values for 10 samples in the left plot. The mid- dle plot displays the accuracy of the predicted system parameters as a percentage, while the right plot illus- trates the predicted distribution versus the actual dis- tribution for this parameter. The results demonstrate a strong overall performance, with only slight discrepan- cies between the predicted and actual distributions and average errors.
   Identifying parameters accurately becomes more chal- lenging when multiple parameters of a system are changed simultaneously. To illustrate this, we consider changing two parameters, s and ?, of the Lorenz system and gen- erating a corresponding dataset. The presented method is expected to identify both parameters and estimate their distributions.
   Figure. 8 presents the results of this experiment. As in Fig. 7, the performance is evaluated by comparing

dy
= x(? - z) - y
dt
dz
= xy - ßz
dt

(20)

the predicted parameters with ground truth values for 10 samples, and by comparing the predicted and real distributions of the parameters. However, due to the added complexity of changing two parameters, the ac-

where s, ? and ß are system parameters, also referred to as simulation parameters in this work denoted by Psim = (s, ?, ß). The Lorenz system exhibits chaotic

curacy decreases for both parameters.
   The left plot of Fig. 8(a) shows the comparison be- tween the predicted and real values of s and ?, while



the middle plot shows the accuracy of the predicted system parameters as a percentage. The right plot dis- plays the predicted and real distributions of s and ?. As expected, the accuracy of the parameter estimation decreases compared to Fig. 7, as the framework has to identify both parameters simultaneously. Despite this, the overall performance is still satisfactory, as the dis- crepancies between the predicted and ground truth data remain relatively small.


5.3 Flow passing over a cylinder

Furthermore, our research presents a series of case stud- ies that illustrate the efficacy of our proposed method for representing flow fields. We have designed our method to be applicable to a wide range of flows, without any restrictions on the type of flow considered. Nonetheless, we have specifically chosen to consider a two-dimensional flow field over a cylinder, which is a classic example commonly used in literature to demonstrate the useful- ness of our approach [36].
   When the fluid passes through the cylinder, it gener- ates a unique phenomenon known as the Karman vortex street, which is a pattern of vortices that form in the wake of the cylinder. This flow pattern is characterized by a steady-state flow with Reynolds numbers ranging between RD = 100 and RD = 200. The Navier-Stocks equations (NS) govern the behavior of the fluid flow and are described by the following equations:

? · U = 0
   
We employed a combination of deep learning tech- niques, including a Convolutional Neural Network (CNN)- Autoencoder to extract compressed and relevant spatial features, a Long Short-Term Memory (LSTM)-Autoencoder to extract temporal features of the flow, and a Neural Network (NF) to interpret these features and determine
the corresponding Reynolds numbers.
   We collected two separate datasets for the velocity fields, one for the stream-wise velocity and one for the transverse velocity, with different Reynolds numbers. Figure. 10 demonstrates that the predicted Reynolds numbers for various Reynolds numbers for transverse velocity fields are very close to the real values. We also present the corresponding errors, as well as a compari- son of the test dataset distribution and the prediction distribution in this figure.
   The network has successfully extracted the spatial and temporal features and estimated the Reynolds num- ber with NF, achieving a relatively low error rate. Sim- ilar performance was achieved for the streamwise veloc- ity (Fig. 9), with an average error of less than 5 percent and the predicted distribution being very close to the real distribution.


5.4 2-D transient cavity problem

The objective of the lid-driven cavity problem is to gain a comprehensive understanding of the fluid's complex movements, which entail the formation of vortices and other flow patterns when the top lid is driven in a linear motion. This problem is classified as a transient phe- nomenon since it involves changes in fluid properties

?U	1
= -? · (UU ) - ?p +
?t	RD

?2U	(21)

over time, in contrast to steady-state flow where the fluid properties remain constant. The Reynolds num- ber in the training data ranges from 1000 to 6500. The

In these equations, U represents the velocity of the
fluid and p represents the pressure. The stream-wise and transverse velocity components are represented by u and v, respectively. The no-slip boundary condition is applied, and the channel is divided into a grid with 96 by 192 evenly spaced points for each sample. By an- alyzing the behavior of the flow field over the cylinder using our proposed method, we aim to showcase the ef- fectiveness and versatility of our approach for studying various types of fluid flows.
   In this section, we aim to quantify the Reynolds number of flows by analyzing their most important spa- tial and temporal features, and linking these features to the flow parameter known as the Reynolds number. To achieve this goal, we created time series of 2-D flow at different Reynolds numbers, ranging from 100 to 200, which encompassed the laminar regime of the flow. We divided these time series into training and test datasets.

channel is partitioned into 192 by 192 grids, and each sample set comprises 30 time steps. The behavior of fluid flow for the cavity problem is illustrated by the Navier-Stokes equations (NS) in equation. (21).
   The performance of the method presented for iden- tifying the system parameter (Reynolds number) in a 2-D transient cavity problem is depicted in Fig. 11. As opposed to the flow over a cylinder case study, the accu- racy decreases when dealing with transient conditions, where vorticity generates more complex patterns.


5.5 Influence of Reynolds numbe on the prediction of parameters for flow case studies

Our framework has a unique ability to identify dynami- cal systems. This means that it can analyze and under- stand the behavior of systems that change over time,



such as fluid flow. In this section, we focus specifically on how the Reynolds number affects the predictions made by our DNN-NF model.
   The Reynolds number is a dimensionless parameter that describes the flow of fluids. It is used to predict the transition from laminar flow to turbulent flow and is a crucial factor in understanding fluid mechanics. To analyze the impact of Reynolds number on our model's predictions, we trained our model on a dataset that included Reynolds numbers ranging from 400 to 3500 for stream-wise and transverse velocity over a cylinder, and between 1000 and 10000 for the cavity problem.It is worth noting that the channel grid remained the same for each case study. Additionally, each sample in the training set comprised 50 and 30 time steps for flow over a cylinder and cavity problem, respectively.
   Figure. 12 presents the accuracy of the results for all three case studies as the Reynolds number increases. The results indicate that as the Reynolds number in- creases, the complexity of the flow also increases, mak- ing it more challenging for our model to accurately cap- ture the most important features of the flow in both the spatial and temporal domains. Therefore, it is essential to consider the Reynolds number when using our model to predict fluid flow parameters, as it can have a signif- icant impact on the accuracy of the results.


6 Conclusion

This study presents a DNN that uses LSTM autoen- coder and Normalizing Flows together to determine the parameters of dynamic systems such as Duffing sys- tems, Lorenz systems, and 2-D flow fields. We observed that by changing two parameters in Lorenz systems, the accuracy of predicted system parameters can decrease due to increased complexity in nonlinear system identi- fication. The spatial and temporal characteristics of the flow fields were successfully extracted through the use of CNN-autoencoders and LSTM-autoencoders, and were linked to Reynolds numbers of 2-D flows via NF. The re- sults showed relatively low errors in predicted distribu- tions, suggesting that the DNN architecture effectively captures the crucial features of the input data and ac- curately computes the relevant system parameters. We also observed that the accuracy of results for the 2-D cavity problem can decrease with increasing Reynolds number.
   It is important to note that our proposed framework has certain potential limitations. Firstly, the range of nonlinearity and Reynolds numbers of interest is lim- ited, which restricts the generalization of the method. Secondly, the accuracy of results decreases significantly

when identifying multiple system parameters, as ob- served in the Lorenz system. Finally, future work should include the validation of our method on real-world dy- namical systems, such as experimental case studies like fluid flows captured by Particle Image Velocimetry (PIV). Moreover, the integration of smart system design prin- ciples with nonlinear dynamics modeling supports inno- vative sustainability strategies, particularly by adapt- ing dynamic solutions for environmental and structural applications [37, 38].


Conflict of interest

The authors declare no conflict of interest.


Data Availability

The data that support the findings of this study are available from the corresponding author upon reason- able request.


Funding

This research was partially funded by the Physics of Ar- tificial Intelligence Program of U.S. Defense Advanced Research Projects Agency (DARPA) and the Michigan Technological University faculty startup fund.


References

1. Gang Liu and Jing Wang. Dendrite net: a white- box module for classification, regression, and sys- tem identification. IEEE Transactions on Cyber- netics, 52(12):13774-13787, 2021.
2. G Giordano and J Sjšoberg. Black-and white-box approaches for cascaded tanks benchmark system identification. Mechanical Systems and Signal Pro- cessing, 108:387-397, 2018.
3. Lennart Ljung. Perspectives on system identifica- tion. Annual Reviews in Control, 34(1):1-12, 2010.
4. Damien Picard, Maarten Sourbron, Filip Jorissen, Ji Cigler, LukŽas Ferkl, Lieve Helsen, et al. Compar- ison of model predictive control performance using grey-box and white box controller models. 2016.
5. Wolfgang Polifke. Black-box system identification for reduced order model construction. Annals of Nuclear Energy, 67:109-128, 2014.
6. Arthur Gretton, Arnaud Doucet, Ralf Herbrich, Pe- ter JW Rayner, and Bernhard Scholkopf. Support



vector regression for black-box system identifica- tion. In Proceedings of the 11th IEEE Signal Pro- cessing Workshop on Statistical Signal Processing (Cat. No. 01TH8563), pages 341-344. IEEE, 2001.
7. Jonas Sjšoberg, Qinghua Zhang, Lennart Ljung, Al- bert Benveniste, Bernard Delyon, Pierre-Yves Glo- rennec, H°akan Hjalmarsson, and Anatoli Juditsky. Nonlinear black-box modeling in system identifica- tion: a unified overview. Automatica, 31(12):1691- 1724, 1995.
8. Junhee Kim and Jerome P Lynch. Subspace system identification of support-excited structures-part i: theory and black-box system identification. Earthquake engineering & structural dynamics, 41(15):2235-2251, 2012.
9. Helon Vicente Hultmann Ayala, Didace Habineza, Micky Rakotondrabe, and Leandro dos San- tos Coelho. Nonlinear black-box system identifica- tion through coevolutionary algorithms and radial basis function artificial neural networks. Applied Soft Computing, 87:105990, 2020.
10. Ingrid Pires, Helon Vicente Hultmann Ayala, and Hans Ingo Weber. Nonlinear ensemble gray and black-box system identification of friction induced vibrations in slender rotating structures. Mechan- ical Systems and Signal Processing, 186:109815, 2023.
11. Daniel Vizer, Guillaume Mercere, Olivier Prot, and JosŽe Ramos. A local approach framework for black- box and gray-box lpv system identification. In 2013 European Control Conference (ECC), pages 1916- 1921. IEEE, 2013.
12. Ehsan Mohammadi and Morteza Montazeri-Gh. A new approach to the gray-box identification of wiener models with the application of gas turbine engine modeling. Journal of Engineering for Gas Turbines and Power, 137(7):071202, 2015.
13. Francesco Beneventi, Andrea Bartolini, Andrea Tilli, and Luca Benini. An effective gray-box iden- tification procedure for multicore thermal model- ing. IEEE Transactions on Computers, 63(5):1097- 1110, 2012.
14. Johan Schoukens and Lennart Ljung. Nonlin- ear system identification: A user-oriented road map. IEEE Control Systems Magazine, 39(6):28- 99, 2019.
15. KA Petsounis and SD Fassois. Parametric time- domain methods for the identification of vibrat- ing structures-a critical comparison and assess- ment. Mechanical Systems and Signal Processing, 15(6):1031-1060, 2001.
16. Anatoli Juditsky, H°akan Hjalmarsson, Albert Ben- veniste, Bernard Delyon, Lennart Ljung, Jonas

Sjšoberg, and Qinghua Zhang. Nonlinear black- box models in system identification: Mathematical foundations. Automatica, 31(12):1725-1750, 1995.
17. Kurt Hornik, Maxwell Stinchcombe, and Halbert White. Universal approximation of an unknown mapping and its derivatives using multilayer feed- forward networks. Neural networks, 3(5):551-560, 1990.
18. Naveed Akhtar and Ajmal Mian. Threat of Ad- versarial Attacks on Deep Learning in Computer Vision: A Survey, feb 2018.
19. Michele Lazzara, Max Chevalier, Michele Colombo, Jasone Garay Garcia, Corentin Lapeyre, and Olivier Teste. Surrogate modelling for an air- craft dynamic landing loads simulation using an lstm autoencoder-based dimensionality reduction approach. Aerospace Science and Technology, 126:107629, 2022.
20. Thomas Simpson, Nikolaos Dervilis, and Eleni Chatzi. Machine learning approach to model order reduction of nonlinear systems via autoencoder and lstm networks. Journal of Engineering Mechanics, 147(10):04021061, 2021.
21. Xinghan Xu and Minoru Yoneda. Multitask air-quality prediction based on lstm-autoencoder model. IEEE transactions on cybernetics, 51(5):2577-2586, 2019.
22. Julen Urain, Michele Ginesi, Davide Tateo, and Jan Peters. Imitationflow: Learning deep sta- ble stochastic dynamic systems by normalizing flows. In 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pages 5231-5237. IEEE, 2020.
23. Ivan Kobyzev, Simon JD Prince, and Marcus A Brubaker. Normalizing flows: An introduction and review of current methods. IEEE transac- tions on pattern analysis and machine intelligence, 43(11):3964-3979, 2020.
24. Shahbaz Abdul Khader, Hang Yin, Pietro Falco, and Danica Kragic. Learning stable normalizing- flow control for robotic manipulation. In 2021 IEEE International Conference on Robotics and Automation (ICRA), pages 1644-1650. IEEE, 2021.
25. Luning Sun and Jian-Xun Wang. Probabilistic sur- rogate modeling of unsteady fluid dynamics using deep graph normalizing flows. Bulletin of the Amer- ican Physical Society, 2022.
26. Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adver- sarial networks. Communications of the ACM, 63(11):139-144, 2020.


27. Olalekan Ogunmolu, Xuejun Gu, Steve Jiang, and Nicholas Gans. Nonlinear systems identification us- ing deep dynamic neural networks. arXiv preprint arXiv:1610.01439, 2016.
28. Daniel Gedon, Niklas Wahlstršom, Thomas B Schšon, and Lennart Ljung. Deep state space models for nonlinear system identification. IFAC- PapersOnLine, 54(7):481-486, 2021.
29. Diederik P Kingma, Max Welling, et al. An intro- duction to variational autoencoders. Foundations and Trends(r) in Machine Learning, 12(4):307-392, 2019.
30. Xirui Ma, Yizhou Lin, Zhenhua Nie, and Hongwei Ma. Structural damage identification based on un- supervised feature-extraction via variational auto- encoder. Measurement, 160:107811, 2020.
31. Xiaoan Yan, Daoming She, Yadong Xu, and Min- ping Jia. Deep regularized variational autoencoder for intelligent fault diagnosis of rotor-bearing sys- tem within entire life-cycle process. Knowledge- Based Systems, 226:107142, 2021.
32. Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio. Density estimation using real nvp. arXiv preprint arXiv:1605.08803, 2016.
33. Laurent Dinh, David Krueger, and Yoshua Bengio. Nice: Non-linear independent components estima- tion. arXiv preprint arXiv:1410.8516, 2014.
34. Bethany Lusch, J Nathan Kutz, and Steven L Brunton. Deep learning for universal linear em- beddings of nonlinear dynamics. Nature communi- cations, 9(1):1-10, 2018.
35. Xavier Glorot and Yoshua Bengio. Understand- ing the difficulty of training deep feedforward neu- ral networks. In Proceedings of the thirteenth in- ternational conference on artificial intelligence and statistics, pages 249-256. JMLR Workshop and Conference Proceedings, 2010.
36. Maziar Raissi, Alireza Yazdani, and George Em Karniadakis. Hidden fluid mechanics: Learning ve- locity and pressure fields from flow visualizations. Science, 367(6481):1026-1030, 2020.
37. Seyedehzahra Shafa. Ranking of smart building de- sign factors with efficient energy management sys- tems and renewable resources. Journal of Design Studio, 6(2):325-335, 2024.
38. Seyedehzahra Shafa. Smart materials in green ar- chitecture: The role of etfe and phase change ma- terials in sustainable building design. Journal of Design Studio, 6(2):383-395, 2024.





